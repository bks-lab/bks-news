---
title: "AI Weekly #7/2026: $380B Bewertung, w√§hrend Software-Aktien fallen"
description: "Anthropic holt $30B bei $380B Valuation, OpenAI beschuldigt DeepSeek der Model-Distillation, Healthcare-AI wird zum Top-Risiko und chinesische Labs bereiten koordinierte Model-Launches vor"
date: 2026-02-15
heroImage: "/images/briefings/2026/02/2026-02-15-hero.jpg"
heroImageAlt: "AI-generierte Illustration zum Thema AI-Funding und Geopolitik"
tags: [ai, weekly, anthropic, funding, deepseek, geopolitics, healthcare, safety, open-source]
type: weekly
sources:
  - title: "Anthropic raises $30 billion in Series G"
    url: "https://www.anthropic.com/news/anthropic-raises-30-billion-series-g"
  - title: "Accelerating mathematical and scientific discovery with Gemini Deep Think"
    url: "https://deepmind.google/blog/accelerating-mathematical-and-scientific-discovery-with-gemini-deep-think/"
  - title: "OpenAI Accuses DeepSeek of Distilling US Models to Gain an Edge"
    url: "https://www.bloomberg.com/news/articles/2026-02-12/openai-accuses-deepseek-of-distilling-us-models-to-gain-an-edge"
  - title: "Misuse of AI Chatbots in Health Care Tops 2026 Health Tech Hazard Report"
    url: "https://healthjournalism.org/blog/2026/02/misuse-of-ai-chatbots-in-health-care-tops-2026-health-tech-hazard-report"
  - title: "China's AI arms race sees sector brace for major flagship model launch week"
    url: "https://www.scmp.com/news/article/3342951/chinas-ai-arms-race-sees-sector-brace-major-flagship-model-launch-week"
  - title: "Testing ads in ChatGPT"
    url: "https://openai.com/news/testing-ads-in-chatgpt"
  - title: "Retiring GPT-4o and older models"
    url: "https://openai.com/index/retiring-gpt-4o-and-older-models/"
  - title: "AI disruption fears slam new corners of the market"
    url: "https://www.cnbc.com/2026/02/12/ai-disruption-fears-slam-new-corners-of-the-market-and-google-reminds-us-why-we-own-it.html"
  - title: "Mistral Voxtral Transcribe 2"
    url: "https://mistral.ai/news/voxtral-transcribe-2"
draft: false
---

# AI Weekly #7/2026

**15. Februar 2026** | Woche 7

---

## Audio-Version

<audio controls preload="metadata" style="width: 100%; margin: 1rem 0;">
  <source src="/bks-news/audio/briefings/2026/02/2026-02-15-ai-weekly-de.mp3" type="audio/mpeg">
</audio>

**16:22 min** | [MP3 herunterladen](/bks-news/audio/briefings/2026/02/2026-02-15-ai-weekly-de.mp3)

---

## TL;DR

- **$380 Milliarden**: Anthropic schlie√üt $30B Series G ab ‚Äì zweitgr√∂√üte Private Tech-Finanzierung aller Zeiten [[1]](#source-1)
- **AI-Geopolitik eskaliert**: OpenAI beschuldigt DeepSeek offiziell vor US-Gesetzgebern der systematischen Model-Distillation [[3]](#source-3)
- **Healthcare-AI-Krise**: ECRI erkl√§rt Chatbot-Misuse zum #1 Patient Safety Risk 2026 ‚Äì genau als FDA Requirements lockert [[4]](#source-4)
- **Chinesische Offensive**: DeepSeek V4, Alibaba Qwen 3.5, ByteDance und Zhipu bereiten koordinierte Launches w√§hrend Lunar New Year vor [[5]](#source-5)

---

## Story der Woche: Anthropic holt $30B bei $380B Valuation ‚Äì und Software-Aktien crashen

Seit seiner Gr√ºndung 2021 ist Anthropic jetzt $380 Milliarden wert. Die Series G Funding Round brachte $30 Milliarden frisches Kapital ein ‚Äì die zweitgr√∂√üte private Tech-Finanzierung der Geschichte, nur √ºbertroffen von OpenAI [[1]](#source-1). Zum Vergleich: Diese Bewertung liegt √ºber BMW, Airbus und Siemens *kombiniert* ‚Äì f√ºr ein Unternehmen, das prim√§r ein Chat-Modell verkauft.

Doch w√§hrend Foundation Model Labs Milliarden einsammeln, erz√§hlt der Aktienmarkt eine andere Geschichte. In derselben Woche fielen Software-Aktien massiv ‚Äì nicht nur Tech, sondern auch Financials, Office Real Estate, Trucking und Logistics [[8]](#source-8). Der Grund: Investoren f√ºrchten, dass AI Agents traditionelle Enterprise-Software obsolet machen.

Diese Paradoxie zeigt die fundamentale Umverteilung von Kapital, die gerade stattfindet. Geld flie√üt weg von Unternehmen, die Software *nutzen*, hin zu denen, die Foundation Models *bauen*. Die M√§rkte preisen nicht nur ein, dass AI disruptiv ist ‚Äì sie bewerten bereits, wer die Gewinner und Verlierer sein werden.

Was macht Anthropic mit $30 Milliarden? Das Unternehmen schweigt sich √ºber Details aus, aber die Timing-Signale sind klar: W√§hrend OpenAI GPT-5.x pusht und DeepSeek V4 n√§chste Woche launcht, braucht Claude massives Kapital f√ºr das Compute-Rennen. Foundation Models sind eine Capital-Intensive Industry geworden ‚Äì wer nicht Milliarden verbrennen kann, spielt nicht mehr mit.

Die $380B Valuation ist keine Bewertung von Anthropic's aktueller Profitabilit√§t ‚Äì es ist eine Wette darauf, dass Claude einer der wenigen √úberlebenden im Foundation Model Consolidation-Prozess sein wird. In einer Welt mit 5-7 Tier-1 Labs ist $380B der Preis f√ºr einen Platz am Tisch.

---

## Weitere Top-Stories

### Google DeepMind: Gemini Deep Think erreicht IMO Gold-Standard und l√∂st offene Erd≈ës-Probleme

Google DeepMind hat Gemini Deep Think vorgestellt ‚Äì ein Reasoning-Modell, das den Gold-Medal-Standard der International Mathematics Olympiad (IMO) erreicht [[2]](#source-2). Noch bemerkenswerter: Das neue "Aletheia" Research Agent Feature l√∂ste vier offene Probleme aus der Erd≈ës Conjectures Database ‚Äì eine Sammlung mathematischer Vermutungen, die teilweise seit Jahrzehnten ungel√∂st sind.

Das ist mehr als ein Benchmark-Win. DeepMind positioniert Gemini Deep Think explizit nicht als "Tool f√ºr Mathematiker", sondern als aktiven wissenschaftlichen Research Partner. Das Modell erreichte au√üerdem Competition-Level-Performance im ICPC (International Collegiate Programming Contest), was zeigt: Die F√§higkeit gilt nicht nur f√ºr formale Mathematik, sondern auch f√ºr algorithmisches Problem-Solving.

Die vier gel√∂sten Erd≈ës-Probleme sind historisch bedeutsam. Paul Erd≈ës war einer der produktivsten Mathematiker des 20. Jahrhunderts ‚Äì seine "Conjectures Database" enth√§lt Hunderte offene Vermutungen, an denen Mathematiker weltweit arbeiten. Dass ein AI-System jetzt eigenst√§ndig L√∂sungen findet, k√∂nnte einen Wendepunkt markieren: AI entwickelt sich vom Assistenten zum Co-Researcher.

F√ºr Scientific AI ist das ein Narrativ-Shift. Bisherige Systeme (AlphaFold, AlphaProof) l√∂sten *spezifische* wissenschaftliche Probleme. Gemini Deep Think zeigt generalisierte Reasoning-F√§higkeit √ºber multiple Dom√§nen hinweg ‚Äì Mathematik, Programming, wissenschaftliche Hypothesen. Das ist die Grundlage f√ºr AI als "allgemeinen wissenschaftlichen Entdecker", nicht nur als Spezialwerkzeug.

---

### OpenAI beschuldigt DeepSeek offiziell der Model-Distillation ‚Äì AI wird geopolitisch

OpenAI hat US-Gesetzgeber offiziell vor DeepSeek gewarnt und dem chinesischen Lab "unfair and increasingly sophisticated methods" vorgeworfen [[3]](#source-3). Der konkrete Vorwurf: DeepSeek extrahiert systematisch Output von US-Modellen (GPT-4, Claude, Gemini), um damit den R1-Nachfolger DeepSeek V4 zu trainieren ‚Äì ein Prozess namens "Model Distillation".

Das ist die erste direkte IP-Accusation zwischen Tier-1 Labs √ºber Staatsgrenzen hinweg. Distillation ist technisch legal (es ist nur Inferenz, kein Weight-Diebstahl), aber OpenAI argumentiert: Wenn DeepSeek systematisch Milliarden API-Calls nutzt, um ein konkurrierendes Modell zu trainieren, ist das unfairer Wettbewerb.

Das Timing ist strategisch. Laut Bloomberg berichtet, wird DeepSeek V4 n√§chste Woche w√§hrend Lunar New Year erwartet [[5]](#source-5) ‚Äì genau wie vor einem Jahr, als DeepSeek-R1 f√ºr Furore sorgte. OpenAI versucht proaktiv, politischen Druck aufzubauen, bevor der Launch erfolgt.

Die geopolitische Dimension ist neu. Bisherige AI-Competition lief auf Benchmark-Ebene ab ‚Äì jetzt wird es zu einem Thema f√ºr Gesetzgeber. OpenAI framed DeepSeek nicht nur als Konkurrent, sondern als staatlich gest√ºtzten Akteur, der US-IP systematisch ausnutzt. Das ist klassische Geopolitics: Technischer Wettbewerb wird zum Staatenwettbewerb.

F√ºr die Industrie bedeutet das: Model Distillation wird ein regulatorisches Thema. Wenn US-Labs erfolgreich argumentieren, dass chinesische Distillation unfair ist, k√∂nnten API-Restrictions folgen ‚Äì was wiederum chinesische Labs zu mehr Autarkie (eigene Infrastruktur) zwingt. Das AI-Rennen fragmentiert sich regional.

---

### Healthcare-AI-Krise: Chatbot-Misuse wird #1 Patient Safety Risk ‚Äì genau als FDA Requirements lockert

ECRI, eine f√ºhrende Nonprofit Patient Safety Organization, hat AI-Chatbot-Misuse zum #1 Health Tech Hazard 2026 erkl√§rt [[4]](#source-4). Das Problem: ChatGPT, Gemini und Microsoft Copilot werden in Healthcare-Settings ohne klinische Aufsicht eingesetzt ‚Äì √Ñrzte und Pfleger nutzen sie f√ºr Diagnosen, Medikations-Empfehlungen und Patientenberatung.

Das Timing ist problematisch. Im Januar 2026 lockerte die FDA Device Requirements f√ºr Clinical Decision Support Tools. Resultat: AI-Tools k√∂nnen jetzt ohne FDA-Vetting in Kliniken eingesetzt werden. Genau in diesem Moment warnt ECRI vor den Risiken.

Die Kernprobleme laut ECRI:
- **Halluzinationen**: ChatGPT erfindet medizinische "Fakten", die plausibel klingen
- **Keine klinische Validierung**: GPT-4 ist kein Medical Device ‚Äì es wurde nie f√ºr Healthcare-Use getestet
- **Fehlende Haftung**: Wenn ein Patient durch AI-Fehlberatung gesch√§digt wird ‚Äì wer ist verantwortlich?

Das ist kein theoretisches Risiko. Healthcare-Professionals berichten bereits von F√§llen, in denen Kollegen ChatGPT-Output 1:1 √ºbernommen haben ‚Äì ohne Fact-Checking. Die FDA-Lockerung verst√§rkt das Problem: Tools, die bisher als "experimental" galten, gelten jetzt als "acceptabel".

Gleichzeitig gibt es positive Beispiele f√ºr AI in Healthcare: Radiologie-Assistenten, die √Ñrzte bei Diagnosen unterst√ºtzen, oder Administrative Copilots, die Dokumentationsaufwand reduzieren. Der Unterschied liegt in der Validierung und der Supervision ‚Äì klinisch gepr√ºfte Tools mit menschlicher Aufsicht funktionieren, General-Purpose Chatbots ohne Oversight sind riskant.

Das zeigt den zentralen Trade-Off: Innovation nicht bremsen vs. Patient Safety gew√§hrleisten. Die FDA versucht, beides zu balancieren, aber der aktuelle Ansatz ‚Äì lockere Requirements f√ºr AI-Tools ‚Äì k√∂nnte zu fr√ºh kommen. Healthcare ist der erste Safety-Critical Use Case, in dem General-Purpose AI massenhaft deployed wird ‚Äì ohne Domain-Specific Safeguards.

---

## Quick Hits

- **OpenAI testet Ads in ChatGPT Free Tier** [[6]](#source-6) ‚Äì Trotz Milliarden-Fundings brauchen alle Labs nachhaltige Revenue Streams. ChatGPT Free bekommt Werbung, Partner zahlen Premium-Raten f√ºr Platzierung.

- **OpenAI retired GPT-4o, GPT-4.1 und o4-mini aus ChatGPT** [[7]](#source-7) ‚Äì Aggressiver Model-Lifecycle: GPT-4o wird nach weniger als einem Jahr aus ChatGPT entfernt. API bleibt, aber ChatGPT pushed User zu GPT-5.x Serie. Signal: OpenAI will schnelle Adoption neuester Modelle erzwingen.

- **Software-Aktien fallen wegen AI Agent Disruption Fears** [[8]](#source-8) ‚Äì Global Software Stocks (Financials, Office Real Estate, Trucking, Logistics) fallen stark. Investoren f√ºrchten: AI Agents ersetzen traditionelle Enterprise Software. Gleiche Woche, in der Anthropic $30B bekommt.

---

## Tool der Woche: Mistral Voxtral Transcribe 2 ‚Äì On-Device Speech-to-Text f√ºr 1/5 der Cloud-Kosten

Mistral AI hat Voxtral Transcribe 2 gelauncht ‚Äì ein Open-Weights Speech-to-Text-Modell, das praktischer und g√ºnstiger ist als alle Cloud-Alternativen [[9]](#source-9).

**Zwei Varianten:**
- **Voxtral Mini**: 13 Sprachen, Speaker Diarization, $0.003/min (vs. GPT-4o mini: ~$0.015/min)
- **Voxtral Realtime**: Sub-200ms Latenz f√ºr Live-Transkription

**Was macht es besonders:**
- **Open-Weights**: Apache 2.0 License ‚Äì kann on-device laufen (Privacy!)
- **Performance**: Outperformt GPT-4o mini bei 1/5 der Kosten
- **Praktisch**: Nicht nur Benchmark-Win ‚Äì echte Kostenersparnis f√ºr Produktiv-Einsatz

**Warum relevant:**
Das ist der Gegentrend zu Cloud-Only AI. W√§hrend OpenAI und Anthropic Milliarden verbrennen f√ºr gr√∂√üere Models, zeigt Mistral: Open-Source kann bei praktischen Tools f√ºhren. On-Device Processing ist Privacy-First (DSGVO-compliant ohne Cloud), g√ºnstiger (keine API-Kosten nach Deployment) und latenzarm (kein Network Round-Trip).

Voxtral Transcribe 2 ist kein Research-Projekt ‚Äì es ist ein Production-Ready Tool, das Unternehmen *heute* deployen k√∂nnen. Das ist die AI-Story, die unter dem Funding-Hype untergeht: Praktische Open-Source-Tools, die echte Probleme l√∂sen.

---

## Fail der Woche: FDA lockert Clinical AI Requirements genau als ECRI vor Chatbot-Misuse warnt

Im Januar 2026 lockerte die FDA Device Requirements f√ºr Clinical Decision Support Tools. Genau im selben Monat warnt ECRI vor AI-Chatbot-Misuse als #1 Health Tech Hazard [[4]](#source-4).

**Timing-Paradox:**
- FDA sagt: "AI-Tools brauchen weniger Vetting"
- ECRI sagt: "AI-Tools ohne Vetting sind die gr√∂√üte Patient-Safety-Gefahr"
- Resultat: ChatGPT/Gemini werden ohne FDA-Check in Kliniken eingesetzt

Das zeigt den Disconnect zwischen Regulierung und Safety-Realit√§t. Policy-Maker wollen "Innovation nicht bremsen", w√§hrend Patient Safety Orgs vor den Risiken warnen. Das Ergebnis ist ein Spannungsfeld: AI-Tools k√∂nnen ohne umfassende Validierung in Healthcare genutzt werden ‚Äì mit Potential f√ºr Haftung und Oversight-Probleme.

Der zentrale Trade-Off: Zu strikte Regulierung bremst Innovation und verhindert positive Use Cases (diagnostische Assistenten, administrative Copilots). Zu lockere Regulierung erm√∂glicht riskante Deployments ohne klinische Validierung. Die FDA versucht, die Balance zu finden ‚Äì aber der aktuelle Ansatz k√∂nnte zu permissiv sein f√ºr Safety-Critical Settings.

---

## Zahl der Woche: $380 Milliarden

Anthropic's Post-Money Valuation nach $30B Series G [[1]](#source-1).

**Warum relevant:**
- Zweitgr√∂√üte Private Tech Valuation nach OpenAI
- Mehr als BMW, Airbus, Siemens *kombiniert*
- F√ºr ein Unternehmen, das prim√§r ein Chat-Modell verkauft

**Der Kontrast:**
Gleiche Woche, in der Anthropic $380B wert ist, fallen Software-Stocks aus Angst vor AI-Disruption [[8]](#source-8). Zeigt Umverteilung von Kapital: Weg von traditioneller Software, hin zu Foundation Model Labs.

$380B ist keine Bewertung von Profit ‚Äì es ist der Preis f√ºr einen Platz im Tier-1 AI Lab Oligopol.

---

## Leseliste

üìñ **[Gemini Deep Think: Mathematical Discovery](https://deepmind.google/blog/accelerating-mathematical-and-scientific-discovery-with-gemini-deep-think/)** ‚Äì Google DeepMind erkl√§rt, wie Aletheia Research Agent offene Erd≈ës-Probleme l√∂ste | *8 min*

üìñ **[OpenAI vs DeepSeek: Model Distillation Accusations](https://www.bloomberg.com/news/articles/2026-02-12/openai-accuses-deepseek-of-distilling-us-models-to-gain-an-edge)** ‚Äì Bloomberg berichtet √ºber die erste geopolitische IP-Accusation zwischen AI Labs | *6 min*

üìñ **[ECRI Health Tech Hazard Report 2026](https://healthjournalism.org/blog/2026/02/misuse-of-ai-chatbots-in-health-care-tops-2026-health-tech-hazard-report)** ‚Äì Warum AI-Chatbots das gr√∂√üte Patient-Safety-Risiko sind | *5 min*

---

## Next Week: Chinese AI Launches & DeepSeek V4

N√§chste Woche startet Lunar New Year ‚Äì und damit die koordinierte Offensive chinesischer AI Labs. Laut South China Morning Post (SCMP), einer in Hongkong ans√§ssigen Zeitung, werden mehrere Major Launches erwartet [[5]](#source-5):

- **DeepSeek V4**: Nachfolger von R1, Context Window 128K ‚Üí 1M Token
- **Alibaba Qwen 3.5**: Flaggschiff-Update
- **ByteDance & Zhipu GLM-5**: Weitere Major Launches

Das ist kein Zufall. Ein Jahr nach DeepSeek's erstem Breakthrough wird Lunar New Year zum "AI Launch Window" ‚Äì √§hnlich wie Apple's September-Events. Zeigt Professionalit√§t und Koordination im chinesischen AI-Sektor.

Wir tracken die Launches und berichten n√§chste Woche.

---

## Behind the AI: Metriken dieser Ausgabe

- **Stories analysiert**: 20 (aus 180+ RSS-Quellen)
- **Finale Selektion**: 5 Top-Stories + 3 Quick Hits
- **Zeitraum**: 2026-02-08 bis 2026-02-15
- **Diversit√§t**: 6 L√§nder (USA, UK, China, Frankreich), 8 Kategorien
- **Sources**: 9 prim√§re Quellen, alle <14 Tage alt

**Story-Auswahl-Kriterien:**
‚úÖ Tier-1 Labs (Anthropic, Google DeepMind, OpenAI)
‚úÖ Open-Source (Mistral)
‚úÖ Geopolitics (USA vs. China)
‚úÖ Regulation (Healthcare AI + FDA)
‚úÖ Business Impact (Funding, Stock Market)

---

## Footer

**AI Weekly** wird von [BKS-Lab](https://bks-lab.com) produziert.

**Newsletter abonnieren:** [bks-lab.com/newsletter](https://bks-lab.com/newsletter)

**Kontakt:** [ai@bks-lab.com](mailto:ai@bks-lab.com)

---

**Rechtliche Hinweise:**
- Dieser Newsletter dient ausschlie√ülich Informationszwecken
- Keine Finanz-, Investitions-, Rechts- oder Gesundheitsberatung
- Alle Angaben ohne Gew√§hr, Stand: 2026-02-15
- Quellen sind durch Hyperlinks gekennzeichnet

---

**Sources:**

<a id="source-1"></a>[1] [Anthropic raises $30 billion in Series G](https://www.anthropic.com/news/anthropic-raises-30-billion-series-g) (2026-02-12)

<a id="source-2"></a>[2] [Accelerating mathematical and scientific discovery with Gemini Deep Think](https://deepmind.google/blog/accelerating-mathematical-and-scientific-discovery-with-gemini-deep-think/) (2026-02-11)

<a id="source-3"></a>[3] [OpenAI Accuses DeepSeek of Distilling US Models to Gain an Edge](https://www.bloomberg.com/news/articles/2026-02-12/openai-accuses-deepseek-of-distilling-us-models-to-gain-an-edge) (2026-02-12)

<a id="source-4"></a>[4] [Misuse of AI Chatbots in Health Care Tops 2026 Health Tech Hazard Report](https://healthjournalism.org/blog/2026/02/misuse-of-ai-chatbots-in-health-care-tops-2026-health-tech-hazard-report) (2026-02-12)

<a id="source-5"></a>[5] [China's AI arms race sees sector brace for major flagship model launch week](https://www.scmp.com/news/article/3342951/chinas-ai-arms-race-sees-sector-brace-major-flagship-model-launch-week) (2026-02-12)

<a id="source-6"></a>[6] [Testing ads in ChatGPT](https://openai.com/news/testing-ads-in-chatgpt) (2026-02-12)

<a id="source-7"></a>[7] [Retiring GPT-4o and older models](https://openai.com/index/retiring-gpt-4o-and-older-models/) (2026-02-13)

<a id="source-8"></a>[8] [AI disruption fears slam new corners of the market](https://www.cnbc.com/2026/02/12/ai-disruption-fears-slam-new-corners-of-the-market-and-google-reminds-us-why-we-own-it.html) (2026-02-12)

<a id="source-9"></a>[9] [Mistral Voxtral Transcribe 2](https://mistral.ai/news/voxtral-transcribe-2) (2026-02-04)

---

*Erstellt mit AI-Unterst√ºtzung | Alle Fakten durch prim√§re Quellen belegt*
